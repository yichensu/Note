# 資料科學與我

目的：整理過去所學跟未來目標之間關聯

## 資料科學最在意：解釋(explanation)、個體預測(prediction)、趨勢預測(forecasting)

### 「解釋」(explanation)：與因果關係共舞的科學方法
> 最重要的是找到因果關係，通常是採用變異數分析

### 「個體預測」(prediction)：讓機器成為你的算命師
> 運用演算法與模型去演算法與模型去抓取重要特徵並分群，以「最小化預測誤差」為終極目標。

### 「趨勢預測」(forecasting)：鑑往知來的趨勢預測
> 最重要的是預測是否準確，可解釋就可以預測，但不能解釋未必不能預測。時間序列通常可以看到整體趨勢變化，但通常許多時間序列的每個時點資料量不夠多（就像我的論文）。
#### some note
* 因果關係、模型解釋預測都是心理學研究非常在意，不同的是，心理學的資料量通常較少，並不會直接運用到機器學習或各類編成方式；另外，因果關係也很難乾淨，甚至並不是直接關注於真正的「預測」，很常都適用相關切入
* R語言Forecast套件的作者是澳洲蒙納許大學的Rob J Hyndman教授所作，是R語言「趨勢預測」最好用的套件。

## 多元迴歸分析變數選擇
### 多元迴歸模型與最小平方法(least square estimation)
> 多元迴歸模型假設母體(population)的性質為：反應變數與解釋變數存在著線性關係，以條件期望值(conditional expectation)的形式表示（看原文）。會蒐集 n 個個體作為隨機樣本(random sample)，樣本回歸模型就是我們很常見的函數式，也會進一步將每個單一個體的反應變數寫成向量，最後就會形成矩陣（要用線性代數理解多元回歸的投影性質）
### 為什麼需要進行變數選擇 (variable selection)
> X是為了解釋Y，若少放重要變項，最小平方法得出的估計式將會是一個偏誤估計式 (biased estimator)，而造成「省略變數的偏誤」(omitted variable bias)。若有太多變數，可能造成模型過度配適 (overfitting) 若有太多變數，可能造成模型；每個變數都會吃掉一些解釋量，若對Y沒有解釋量，根本不用放入，若對Y有解釋量但不重要，就會造成誤差變大，損害其他重要變項的估計品質

### 變數選擇方法：「子集合選取法」、「正規化」、「資訊準則法」
#### 「解釋」的變數選擇：子集合選取法 (subset selection)

---
* 一開始從數據分析樹們比較簡單？
* 資料探勘、機器學習、演算法都是資料科學家重要工具
* 初學者可以先從較廣的方面理解
* 可以透過競賽去學習與累積實力

目前大目標：


